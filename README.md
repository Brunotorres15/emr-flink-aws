# Automatizando Infraestrutura de Processamento de Dados com AWS EMR e Apache Flink ğŸš€

![alt text](./images/image.png)

### Qual o produto final desenvolvido?
- â™¨ï¸ Foi criada uma soluÃ§Ã£o de infraestrutura para processamento de dados, que pode rapidamente ser provisionada com dois comandos(sim, isso mesmo, dois comandos), podendo ser utilizada e adaptada para os mais variados tipos de demandas, seja para processamento moderado, atÃ© grandes volumes de dados.


### Qual o objetivo principal ?
- ğŸš€ Esse projeto tem o objetivo principal de demonstrar um exemplo da automatizaÃ§Ã£o, configuraÃ§Ã£o e o gerenciamento da infraestrutura necessÃ¡ria para executar pipelines de processamento de dados em lote e streaming, capazes de lidar com grandes volumes de dados com baixa latÃªncia.


- ğŸ“Œ O processamento a ser realizado neste projeto, Ã© um processamento simples visando a demonstraÃ§Ã£o de como seria esse provisionamento e automaÃ§Ã£o fim-a-fim de uma infraestrutura real! Com seu prÃ³prio script (em pyspark por exemplo), e claro, ajuste nas capacidades dos clusters (o que pode ser feito pelo prÃ³prio cÃ³digo ğŸ˜‰), a infraestrutura aprendida aqui pode ser utilizada para suportar pipelines de dados super robustas.
- âš ï¸ **Cuidado!** Os serviÃ§os provisionados por esse projeto **NÃƒO** sÃ£o gratuitos, apesar de ser um exemplo simples, justamente pra nÃ£o incorrer grandes custos durante o estudo, deixar a infraestrutura rodando por cerca de 1 hora, pode gerar custos entre $0.70 a $1.10 DÃ³lares (por hora), nÃ£o Ã© muito, mas nÃ£o vai esquecer o cluster ligado em ğŸš¨.

### O que vocÃª verÃ¡ aqui?

- ğŸ“Œ DemonstraÃ§Ã£o passo a passo de como subir a infraestrutura, executar as intruÃ§Ãµes, como submeter steps para executar o processamento desejado e, apÃ³s isso, destruiÃ§Ã£o da infraestrutura.
### O que nÃ£o terÃ¡ aqui?
- ğŸ“Œ Tutorial de como codar toda essa soluÃ§Ã£o do zero, seria necessÃ¡rio um curso pra isso.

# Tecnologias Utilizadas

ğŸ“Œ AWS EMR

*O Amazon Elastic MapReduce (EMR) Ã© um serviÃ§o de processamento de big data que facilita a execuÃ§Ã£o de frameworks como Apache Hadoop, Apache Spark, Apache HBase, Apache Flink e Presto na nuvem AWS. Ele simplifica o processamento de grandes volumes de dados e fornece escalabilidade automÃ¡tica.*

ğŸ“Œ Apache Flink

*Apache Flink Ã© um framework de processamento de fluxo e lote de dados em tempo real. Ele oferece capacidades avanÃ§adas para processamento de eventos, anÃ¡lise de dados em tempo real e operaÃ§Ãµes de estado, permitindo aplicaÃ§Ãµes de alta performance e baixa latÃªncia.*

ğŸ“ŒHadoop

*Apache Hadoop Ã© uma plataforma de software de cÃ³digo aberto para armazenamento e processamento de grandes conjuntos de dados. Ele usa um sistema distribuÃ­do de arquivos (HDFS) e um modelo de programaÃ§Ã£o MapReduce para processamento paralelo em clusters de computadores.*

ğŸ“Œ Docker

*Docker Ã© uma plataforma que facilita a criaÃ§Ã£o, a distribuiÃ§Ã£o e a execuÃ§Ã£o de aplicativos em contÃªineres. Os contÃªineres Docker permitem a execuÃ§Ã£o consistente de aplicaÃ§Ãµes em diferentes ambientes, garantindo isolamento e portabilidade.*

ğŸ“ŒTerraform

*Terraform Ã© uma ferramenta de infraestrutura como cÃ³digo (IaC) que permite criar, gerenciar e versionar a infraestrutura de forma declarativa. Com o Terraform, vocÃª pode definir a infraestrutura usando arquivos de configuraÃ§Ã£o e automatizar a provisÃ£o e gerenciamento de recursos em provedores de nuvem como AWS, Azure e Google Cloud.*

ğŸ“ŒDemais Recursos da AWS

*Outros recursos da AWS sÃ£o necessÃ¡rios para subir essa infraestrutura, como instÃ£ncias EC2(utilizadas como cluster para o EMR), Vpc, IAM Roles, Grupos de SeguranÃ§a, etc...*

DocumentaÃ§Ã£o:
* [AWS EMR](https://aws.amazon.com/pt/emr/)
* [Apache Flink](https://flink.apache.org)
* [Hadoop](https://hadoop.apache.org)
* [Docker](https://www.docker.com/)
* [Terraform](https://www.terraform.io)


## O que Ã© necessÃ¡rio pra executar o projeto?

DependÃªncias necessÃ¡rias para rodar o projeto.

* Docker Desktop
* Conta na AWS

## Como Montar o Ambiente âœ…

### Clone o RepositÃ³rio
```
git clone https://github.com/Brunotorres15/emr-flink-aws.git
```

### Execute o comando abaixo para criar a imagem Docker

```
docker build -t emr-flink-aws-image:v1 .
```

### Execute o comando abaixo para criar o container Docker

```
docker run -dit --name emr-flink-aws-container -v ./IaC:/iac emr-flink-aws-image:v1 /bin/bash
```
NOTA: No Windows vocÃª deve substituir ./IaC pelo caminho completo da pasta

### Acesse o container docker e verifique a versÃ£o do Terraform com o comando

```
terraform version
```

## Provisionando uma Infraestrutura de processamento com AWS EMR e Apache Flink âœ…


ğŸ“Œ Crie um bucket no S3 chamado **emr-logs-\<account-id>** e configure no arquivo **emr.tf**,
utilizaremos este bucket como uma fonte externa para guardar os logs do cluster. 

### Configure as suas credenciais de acesso Ã  AWS via cli
```
aws configure
```

### Inicialize o Terraform
```
terraform init
```
### ğŸš€ Provisionando toda uma infraestrutura com dois comandos!

#### Cria o Plano de ExecuÃ§Ã£o do terraform e salva em disco

```
terraform plan -var-file config.tfvars -out terraform.tfplan
```
Obs: 
- *-var-file Ã© pra indicar qual arquivo de configuraÃ§Ã£o estamos utilizando pra buscar aos valores das variÃ¡veis que setamos.* 
- -out Ã© o arquivo de saÃ­da que vai guardar nosso plano de execuÃ§Ã£o.

### Executa o apply do plano de execuÃ§Ã£o, informando nomavente o arquivo onde estÃ£o as variÃ¡veis (com auto-approve)

```
terraform apply -auto-approve -var-file config.tfvars
```

### Opcional: Executa o apply com o arquivo de variÃ¡veis (sem auto-approve)
```
terraform apply -var-file config.tfvars
```

### Cluster de pÃ© e pronto pra receber os steps pra execuÃ§Ã£o
![alt text](./images/image-6.png)

# ğŸ˜µâ€ğŸ’« TÃ¡, mas o que isso quer dizer?

#### ğŸ“Œ Isso significa que com o Terraform, temos em nossas mÃ£os toda uma infraestrutura robusta, personalizÃ¡vel e escalÃ¡vel, que podemos provisionar e destruir sempre que precisarmos dela, evitando assim, ter que provisionar tudo na mÃ£o toda vez que precisar subir clusters em nuvem. ğŸ¤¯

## Agora que temos nossa infraestrutura, vamos acessar via SSH o cluster master e realizar alguns processamentos de exemplo âœ…

#### ğŸ“Œ No container Docker navegue atÃ© a pasta onde estÃ£o as chaves criadas no deploy do cluster ("generated/ssh")

#### Ajusta o privilÃ©gio da chave 
```
chmod 400 deployer
```

#### Conecta via SSH (coloque abaixo o endereÃ§o do seu cluster)
```
ssh -i deployer hadoop@ec2-3-14-29-59.us-east-2.compute.amazonaws.com
```

## Exemplo de execuÃ§Ã£o de steps no EMR com o Apache Flink âœ…

- Obs: Vamos usar o Hadoop (HDFS) pra armazenar o arquivo que vamos processar, desta forma ele Ã© acessÃ­vel por todas as instÃ¢ncias do cluster. 
### Crie uma pasta como input no HDFS
```
hdfs dfs -mkdir /user/root/input
```

### Crie um arquivo txt como por exemplo:
```
vi dados.txt
```
- utilizei o vi para criar um arquivo de texto, mas vocÃª pode utilizar qualquer outro editor de texto, texto de exemplo:

```
IaC (Infraestrutura Como CÃ³digo) nasceu no universo DevOps, mas rapidamente chegou Ã  Ã¡rea de dados para ajudar no trabalho de Engenheiros de Dados, Engenheiros de Machine Learning, Arquitetos de Dados, Cientistas de Dados e Engenheiros de IA.

Neste curso vocÃª vai desenvolver suas habilidades com Terraform, uma ferramenta open-source que permite definir a infraestrutura como cÃ³digo usando uma linguagem simples e declarativa e implantar e gerenciar essa infraestrutura em uma variedade de provedores de cloud computing (em nuvem pÃºblica ou privada) e virtualizaÃ§Ã£o, com apenas alguns comandos.

AlÃ©m do Terraform vocÃª vai trabalhar com AWS, Azure e Databricks atravÃ©s de diversos Labs e Projetos. O conhecimento que vocÃª irÃ¡ adquirir neste curso vai colocÃ¡-lo muito a frente de outros profissionais do mercado, aumentando de forma considerÃ¡vel sua empregabilidade na Ã¡rea de dados, independente da sua funÃ§Ã£o.

Este Ã© um curso realmente Ãºnico, praticamente um trabalho de consultoria para vocÃª, no padrÃ£o de qualidade da Data Science Academy.
```

### Copie o arquivo criado para o 

```
hdfs dfs -put dados.txt /user/root/input
```

### Vamos contar o nÃºmero de ocorrÃªncias de cada palavra no arquivo, usando um script padrÃ£o que jÃ¡ vem com o Apache Flink
```
flink run -m yarn-cluster /usr/lib/flink/examples/streaming/WordCount.jar --input hdfs:///user/root/input/dados.txt --output hdfs:///user/root/saida/
```
- Obs: `flink run` Este Ã© o comando principal para submeter um job para o Apache Flink. O run indica que vocÃª estÃ¡ executando um job de Flink.
- `-m yarn-cluster`  opÃ§Ã£o -m (ou --jobmanager) especifica o modo de execuÃ§Ã£o do Flink. Neste caso, yarn-cluster indica que o Flink estÃ¡ sendo executado no modo cluster gerenciado pelo YARN (Yet Another Resource Negotiator), que Ã© um gerenciador de recursos do Hadoop. O Flink executarÃ¡ o job em um cluster YARN.
- `/usr/lib/flink/examples/streaming/WordCount.jar` Este Ã© o caminho para o arquivo JAR (Java ARchive) que contÃ©m o cÃ³digo do job de Flink que serÃ¡ executado. No exemplo, WordCount.jar Ã© um exemplo padrÃ£o que conta o nÃºmero de ocorrÃªncias de cada palavra em um fluxo de dados.
`--input hdfs:///user/root/input/dados.txt` O parÃ¢metro --input especifica o caminho para o arquivo de entrada que o job de Flink usarÃ¡. No caso, o arquivo dados.txt estÃ¡ localizado no HDFS (Hadoop Distributed File System) no diretÃ³rio /user/root/input/. HDFS Ã© um sistema de arquivos distribuÃ­do que armazena grandes volumes de dados.
- `--output hdfs:///user/root/saida/` O parÃ¢metro - --output especifica o caminho onde os resultados do job de Flink serÃ£o armazenados. Neste caso, os resultados serÃ£o armazenados no HDFS no diretÃ³rio /user/root/saida/.

### Resultado da ExecuÃ§Ã£o do Step no Cluster ERM na AWS
![alt text](./images/image-5.png)

### Veja o nome dos arquivos de saÃ­da.
```
hdfs dfs -ls /user/root/saida/
```

### Copie o arquivo de saÃ­da no HDFS para o sistema de arquivos.
```
hdfs dfs -get caminho-e-nome-arquivo-no-HDFS
```
### FaÃ§a um cat (comando linux) do arquivo pra ver o resultado:
```
(como,1)
(c,1)
(digo,1)
(devops,1)
(chegou,1)
(rea,1)
(machine,1)
(arquitetos,1)
(cientistas,1)
(e,1)
(desenvolver,1)
(habilidades,1)
(com,1)
(terraform,1)
(uma,1)
(que,1)
(permite,1)
(definir,1)
(como,2)
(c,2)
(digo,2)
(usando,1)
(uma,2)
(linguagem,1)
(simples,1)
(e,2)
(e,3)
(implantar,1)
(e,4)
(gerenciar,1)
(em,1)
(uma,3)
(variedade,1)
(provedores,1)
(cloud,1)
(computing,1)
(em,2)
(ou,1)
(privada,1)
(e,5)
(virtualiza,1)
(o,1)
(com,2)
(al,1)
(do,1)
(terraform,2)
(trabalhar,1)
(com,3)
(e,6)
(e,7)
(o,2)
(que,2)
(ir,1)
(adquirir,1)
(lo,1)
(profissionais,1)
(do,2)
(mercado,1)
(aumentando,1)
(forma,1)
(sua,1)
(empregabilidade,1)
(rea,2)
(da,1)
(sua,2)
(o,3)
(este,1)
(praticamente,1)
(o,4)
(qualidade,1)
(da,2)
(data,1)
(science,1)

```

___

## â­ï¸ Outras formas de enviar essas estapas pro cluster sem Acessar via SSH
 
### ****Os comandos abaixo devem ser executados no container Docker (mÃ¡quina cliente), dessa forma vocÃª nÃ£o precisaria acessar o master node via ssh.****

#### Utilizando a prÃ³pria cli da AWS pra adicionar os steps
(Lembre de colocar o ID do seu cluster EMR).
```
aws emr add-steps --cluster-id j-NF8210OHK2AH \
--steps Type=CUSTOM_JAR,Name=Job1_P1,Jar=command-runner.jar,\
Args="flink","run","-m","yarn-cluster",\
"/usr/lib/flink/examples/streaming/WordCount.jar",\
"--input","hdfs:///user/root/input/dados.txt","--output","hdfs:///user/root/saidajob1/" \
--region us-east-2
```
___

### Utilizando o S3 como input e output dos dados

***Resultado:***
![alt text](./images/image-3.png)

```
aws emr add-steps --cluster-id j-32R8POOJ1HIMA \
--steps Type=CUSTOM_JAR,Name=Job2_P1,Jar=command-runner.jar,\
Args="flink","run","-m","yarn-cluster",\
"/usr/lib/flink/examples/streaming/WordCount.jar",\
"--input","s3://bucket-logs-<account-id>/dados.txt","--output","s3://bucket-logs-<account-id>/" \
--region us-east-2
```
- ApÃ³s o processamento ter sido finalizado, foi criado automatizamente uma pasta 2024-07-20--23 (que no seu pode ter outro nome) com o resultado do processamento que foi realizado.

### âœ… E pronto! Dessa forma utilizamos o Apache Flink pra realizar um processamento em um Cluster EMR e temos o resultado deste processamento!  âœ…

- ğŸ“Œ Vale ressaltar que foi um exemplo simples de processamento, com a ideia de mostrar como seria essa implementaÃ§Ã£o e execuÃ§Ã£o dessas rotinas.
- ğŸ“Œ Utilizando algum outro script e grandes conjuntos de dados por exemplo, esta mesma lÃ³gica serviria pra realizar um processamento em larga escala (temos que comeÃ§ar pequeno e ir escalando ğŸ˜‰ ); Como por exemplo, submeter um script em pyspark pra processamendo da Raw no S3 e escrever em Delta na Bronze.

# âš ï¸ Destruindo a infraestrutura com dois comandos.

### Cria o Plan para o destroy e salva em disco
```
terraform plan -destroy -var-file config.tfvars -out terraform.tfplan
```

### Executa o destroy
```
terraform apply terraform.tfplan
```


### Agora sempre que precisar dela, basta fazer o Terraform apply como foi mostrado no comeÃ§o do projeto, e com dois comandos, vocÃª teria toda essa infraestrutura provisionada novamente ğŸ˜‰.



## FIM