# Automatizando Infraestrutura de Processamento de Dados com AWS EMR e Apache Flink ğŸš€

![alt text](./images/image.png)

### Qual o produto final desenvolvido?
- â™¨ï¸ Foi criada uma soluÃ§Ã£o de infraestrutura para processamento de dados, que pode rapidamente ser provisionada com dois comandos(sim, isso mesmo, dois comandos), podendo ser utilizada e adaptada para os mais variados tipos de demandas, seja para processamento moderado, atÃ© grandes volumes de dados.


### Qual o objetivo principal ?
- ğŸš€ Esse projeto tem o objetivo principal de demonstrar um exemplo da automatizaÃ§Ã£o, configuraÃ§Ã£o e o gerenciamento da infraestrutura necessÃ¡ria para executar pipelines de processamento de dados em lote e streaming, capazes de lidar com grandes volumes de dados com baixa latÃªncia.


- ğŸ“Œ O processamento a ser realizado neste projeto, Ã© um processamento simples visando a demonstraÃ§Ã£o de como seria esse provisionamento e automaÃ§Ã£o fim-a-fim de uma infraestrutura real! Com seu prÃ³prio script (em pyspark por exemplo), e claro, ajuste nas capacidades dos cluster (pelo prÃ³prio cÃ³digo), a infraestrutura aprendida aqui pode ser utilizada para suportar pipelines de dados super robustas.
- âš ï¸ **Cuidado!** Os serviÃ§os provisionados por esse projeto **NÃƒO** sÃ£o gratuitos, apesar de ser um exemplo simples, justamente pra nÃ£o incorrer grandes custos durante o estudo, deixar a infraestrutura rodando por cerca de 1 hora, pode gerar custos entre $0.70 a $1.10 DÃ³lares (por hora), nÃ£o Ã© muito, mas nÃ£o vai esquecer o cluster ligado em ğŸš¨.

### O que vocÃª verÃ¡ aqui?

- ğŸ“Œ DemonstraÃ§Ã£o passo a passo de como subir a infraestrutura, executar as intruÃ§Ãµes, como submeter steps para executar o processamento desejado e, apÃ³s isso, destruiÃ§Ã£o da infraestrutura.
### O que nÃ£o terÃ¡ aqui?
- ğŸ“Œ Tutorial de como codar toda essa soluÃ§Ã£o do zero, seria necessÃ¡rio um curso pra isso.

# Tecnologias Utilizadas

ğŸ“Œ AWS EMR

*O Amazon Elastic MapReduce (EMR) Ã© um serviÃ§o de processamento de big data que facilita a execuÃ§Ã£o de frameworks como Apache Hadoop, Apache Spark, Apache HBase, Apache Flink e Presto na nuvem AWS. Ele simplifica o processamento de grandes volumes de dados e fornece escalabilidade automÃ¡tica.*

ğŸ“Œ Apache Flink

*Apache Flink Ã© um framework de processamento de fluxo e lote de dados em tempo real. Ele oferece capacidades avanÃ§adas para processamento de eventos, anÃ¡lise de dados em tempo real e operaÃ§Ãµes de estado, permitindo aplicaÃ§Ãµes de alta performance e baixa latÃªncia.*

ğŸ“ŒHadoop

*Apache Hadoop Ã© uma plataforma de software de cÃ³digo aberto para armazenamento e processamento de grandes conjuntos de dados. Ele usa um sistema distribuÃ­do de arquivos (HDFS) e um modelo de programaÃ§Ã£o MapReduce para processamento paralelo em clusters de computadores.*

ğŸ“Œ Docker

*Docker Ã© uma plataforma que facilita a criaÃ§Ã£o, a distribuiÃ§Ã£o e a execuÃ§Ã£o de aplicativos em contÃªineres. Os contÃªineres Docker permitem a execuÃ§Ã£o consistente de aplicaÃ§Ãµes em diferentes ambientes, garantindo isolamento e portabilidade.*

ğŸ“ŒTerraform

*Terraform Ã© uma ferramenta de infraestrutura como cÃ³digo (IaC) que permite criar, gerenciar e versionar a infraestrutura de forma declarativa. Com o Terraform, vocÃª pode definir a infraestrutura usando arquivos de configuraÃ§Ã£o e automatizar a provisÃ£o e gerenciamento de recursos em provedores de nuvem como AWS, Azure e Google Cloud.*

ğŸ“ŒDemais Recursos da AWS

*Outros recursos da AWS sÃ£o necessÃ¡rios para subir essa infraestrutura, como instÃ£ncias EC2(utilizadas como cluster para o EMR), Vpc, IAM Roles, Grupos de SeguranÃ§a, etc...*

DocumentaÃ§Ã£o:
* [AWS EMR](https://aws.amazon.com/pt/emr/)
* [Apache Flink](https://flink.apache.org)
* [Hadoop](https://hadoop.apache.org)
* [Docker](https://www.docker.com/)
* [Terraform](https://www.terraform.io)


## O que Ã© necessÃ¡rio pra executar o projeto?

DependÃªncias necessÃ¡rias para rodar o projeto.

* Docker Desktop
* Conta na AWS

## Como Montar o Ambiente âœ…

### Clone o RepositÃ³rio
```
git clone https://github.com/Brunotorres15/emr-flink-aws.git
```

### Execute o comando abaixo para criar a imagem Docker

```
docker build -t emr-flink-aws-image:v1 .
```

### Execute o comando abaixo para criar o container Docker

```
docker run -dit --name emr-flink-aws-container -v ./IaC:/iac emr-flink-aws-image:v1 /bin/bash
```
NOTA: No Windows vocÃª deve substituir ./IaC pelo caminho completo da pasta

### Acesse o container docker e verifique as versÃµes do Terraform e do AWS CLI com os comandos

```
terraform version
aws --version
```

## Provisionando uma Infraestrutura de processamento com AWS EMR e Apache Flink âœ…


ğŸ“Œ Crie um bucket no S3 chamado **bucket-logs-\<account-id>** e configure no arquivo **emr.tf**,
utilizaremos este bucket como uma fonte externa para guardar os logs do cluster. 

### Configure as suas credenciais de acesso Ã  AWS via cli
```
aws configure
```

### Inicializa o Terraform
```
terraform init
```
### ğŸš€ Provisionando toda uma infraestrutura com dois comandos!

#### Cria o Plano de ExecuÃ§Ã£o do terraform e salva em disco

```
terraform plan -var-file config.tfvars -out terraform.tfplan
```
Obs: 
- *-var-file Ã© pra indicar qual arquivo de configuraÃ§Ã£o estamos utilizando pra buscar aos valores das variÃ¡veis que setamos.* 
- -out Ã© o arquivo de saÃ­da que vai guardar nosso plano de execuÃ§Ã£o.

### Executa o apply do plano de execuÃ§Ã£o, informando nomavente o arquivo onde estÃ£o as variÃ¡veis (com auto-approve)

```
terraform apply -auto-approve -var-file config.tfvars
```

### Opcional: Executa o apply com o arquivo de variÃ¡veis (sem auto-approve)
```
terraform apply -var-file config.tfvars
```

# ğŸ˜µâ€ğŸ’« TÃ¡, mas o que isso quer dizer?

#### ğŸ“Œ Isso significa que com o Terraform, temos em nossas mÃ£os toda uma infraestrutura robusta, personalizÃ¡vel e escalÃ¡vel, que podemos provisionar e destruir sempre que precisarmos dela, evitando assim, ter que provisionar tudo na mÃ£o toda vez que precisar subir clusters em nuvem. ğŸ¤¯

## Agora que temos nossa infraestrutura, vamos acessar via SSH o cluster master e realizar alguns processamentos de exemplo âœ…

#### ğŸ“Œ No container Docker navegue atÃ© a pasta onde estÃ£o as chaves criadas no deploy do cluster ("generated/ssh")

#### Ajusta o privilÃ©gio da chave 
```
chmod 400 deployer
```

#### Conecta via SSH (coloque abaixo o endereÃ§o do seu cluster)
```
ssh -i deployer hadoop@ec2-3-14-29-59.us-east-2.compute.amazonaws.com
```

## Exemplo de execuÃ§Ã£o de steps no EMR com o Apache Flink âœ…

- Obs: Vamos usar o Hadoop (HDFS) pra armazenar o arquivo que vamos processar, desta forma ele Ã© acessÃ­vel por todas as instÃ¢ncias do cluster. 
### Crie uma pasta como input no HDFS
```
hdfs dfs -mkdir /user/root/input
```

### Crie um arquivo de texte como por exemplo:
```
vi dados.txt
```
- utilizei o vi para criar um arquivo de texto, mas vocÃª pode utilizar qualquer outro editor de texto, texto de exemplo:

```
IaC (Infraestrutura Como CÃ³digo) nasceu no universo DevOps, mas rapidamente chegou Ã  Ã¡rea de dados para ajudar no trabalho de Engenheiros de Dados, Engenheiros de Machine Learning, Arquitetos de Dados, Cientistas de Dados e Engenheiros de IA.
```

### Copie o arquivo criado para o 

```
hdfs dfs -put dados.txt /user/root/input
```

### Vamos contar o nÃºmero de ocorrÃªncias de cada palavra no arquivo usando Apache Flink
```
flink run -m yarn-cluster /usr/lib/flink/examples/streaming/WordCount.jar --input hdfs:///user/root/input/dados.txt --output hdfs:///user/root/saida/
```

### Copie o arquivo do HDFS para o sistema de arquivos.
```
hdfs dfs -get nome-arquivo-no-HDFS
```

### âœ… E pronto! Dessa forma utilizamos o Apache Flink pra realizar um processamento em um Cluster EMR e temos o resultado deste processamento!  âœ…
- ğŸ“Œ Vale ressaltar que foi um exemplo simples de processamento, com a ideia de mostrar como seria essa implementaÃ§Ã£o e execuÃ§Ã£o dessas rotinas.
- ğŸ“Œ Utilizando algum outro script e grandes conjuntos de dados por exemplo, esta mesma lÃ³gica serviria pra realizar um processamento em larga escala (temos que comeÃ§ar pequeno e ir escalando ğŸ˜‰ )! 

## â­ï¸ Outras formas de enviar essas estapas pro cluster sem Acessar via SSH
 
#### Os comandos abaixo devem ser executados no container Docker (mÃ¡quina cliente), dessa forma vocÃª nÃ£o precisaria acessar o master node via ssh.

Utilizando a prÃ³pria cli da AWS pra adicionar os steps
(Lembre de colocar o ID do seu cluster EMR).
```
aws emr add-steps --cluster-id j-NF8210OHK2AH \
--steps Type=CUSTOM_JAR,Name=Job1_P1,Jar=command-runner.jar,\
Args="flink","run","-m","yarn-cluster",\
"/usr/lib/flink/examples/streaming/WordCount.jar",\
"--input","hdfs:///user/root/input/dados.txt","--output","hdfs:///user/root/saidajob1/" \
--region us-east-2
```

utilizando o S3 como input e output dos dados e resultados.
![alt text](./images/image-1.png)
```
aws emr add-steps --cluster-id j-32R8POOJ1HIMA \
--steps Type=CUSTOM_JAR,Name=Job2_P1,Jar=command-runner.jar,\
Args="flink","run","-m","yarn-cluster",\
"/usr/lib/flink/examples/streaming/WordCount.jar",\
"--input","s3://bucket-logs-<account-id>/dados.txt","--output","s3://bucket-logs-<account-id>/" \
--region us-east-2
```


# âš ï¸ Destruindo a infraestrutura com dois comandos.

### Cria o Plan para o destroy e salva em disco
```
terraform plan -destroy -var-file config.tfvars -out terraform.tfplan
```

### Executa o destroy
```
terraform apply terraform.tfplan
```


### Agora sempre que precisar dela, basta fazer o Terraform apply como foi mostrado no comeÃ§o do projeto, e com dois comandos, vocÃª teria toda essa infraestrutura provisionada novamente ğŸ˜‰.



## FIM